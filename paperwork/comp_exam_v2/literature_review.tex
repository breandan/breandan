%! Author = breandanconsidine
%! Date = 8/9/21

% Preamble
\documentclass[10pt]{article}

% Packages
\usepackage{amsmath}

% Document
\title{Programming in the Age of Intelligent Machines}
\author{Breandan Considine}
\date{\today}

\begin{document}
  \maketitle
  \section{Introduction}

Since the invention of modern computers in the mid 20th century, computer programming has undergone a number of paradigm shifts. From the rise of functional programming, to dynamic, object-oriented, and type-level programming, to the availability of myriad tools and frameworks -- its practitioners have witnessed a veritable Renaissance in the art of computer programming. With each of these paradigm shifts, programmers have realized new conceptual frameworks for reasoning and expressing their ideas more clearly and concisely.

Over the last few years, another paradigm shift has been set in motion, with significant implications for how we think about and write programs in the coming century. By most measures, computers have grown steadily more intelligent and capable of assisting programmers with mentally taxing chores. For example, intelligent programming tools (IPTs) powered by neural language models have this year helped over 10 million unique human beings program computers. As IPTs help digitally illiterate communities to discover their innate aptitude for computer programming, this population will continue to rise.

Computer programming is a uniquely creative exercise among the range of human activities. It channels our innate linguistic, logical, imaginative, and social abilities to bring abstract ideas into reality, and ultimately, gives humans the freedom to create new realities of their own design. In collaboration with other humans and the increasing participation of IPTs, vast and elaborate virtual worlds have been manufactured, where the majority of humankind now chooses to spend their daily lives. With the expanding opportunities these new digital frontiers promise to offer, their population too will continue to grow.

Today IPTs share an equal role in shaping many aspects of computer programming, from knowledge discovery to API design, and program synthesis to validation and verification. However, this balance is shifting beneath our feet. Once its creators, programmers are now primarily consumers of information provided by an IPT, and increasingly rely on them to perform their daily work. With the unique opportunities and risks this partnership presents, what division of labor should exist between humans and our new coding collaborators? This is the question we have set out to understand in the following literature review.

  \section{Neural Language Models for Source Code}

Programming researchers have long held an interest in using intelligent tools to help write programs~\cite{bras1993artificial}. Due to fundamental limitations in data and processing power, many of these ambitions had not come to fruition until the last few years, thanks the availability of \textit{big code}~\cite{allamanis2018survey}, the development of differentiable programming libraries for gradient-based learning, and attention-based models~\cite{vaswani2017attention}, among other technical achievements such as more efficient representations and learning algorithms. Armed with this new repertoire, programming researchers have gained a renewed interest in neural program synthesis.

 Following their initial success in natural language, a great number of transformer models were published, and rapid progress occurred in the design and application these models to source code, as well as industrial transfer where this technology is now trained and deployed to millions of programmers worldwide~\cite{chen2021evaluating}. Such models are capable of inferring programmer intent and completing long fragments of source code given some contextual information.

The problem comes down to a question of grammar induction. Based on empirical results, fixed-precision transformers (e.g. GPT-2, BERT) are thought capable of recognizing the class of counter languages, i.e. somewhere between context-free and context-sensitive, although this characterization requires a more careful theoretical investigation. For source code typically stored on GitHub, this class would appear to suffice -- models trained on such datasets are generally capable of rudimentary program sketching and boilerplate code completion, although more complex fragments require additional oversight.

An important shortcoming of the imitation learning model is the question of data provenance. Even if the training data is syntactically clean, constraints on the class of valid programs are not well-defined. As a consequence, there exists a large fragment of syntactically valid programs which are semantically unsound, i.e. which throw runtime errors at best, or would appear to work at first glance, but are in fact broken in a subtle manner. Like most unsupervised language models of its kind, performance is highly sensitive to the dataset quality, as common errors in the training data can introduce subtle mistakes.

The vast majority of modern programming consists of writing ceremonial boilerplate, tasks for which neural language models are well-suited. A tremendous amount of human labor is spent on such chores, and reallocating those resources towards more intellectually stimulating tasks may encourage more humans to become programmers who otherwise lack the patience or interest. By removing these barriers to entry, programmers can more quickly arrive at the rewarding parts of program design and implementation.

Nevertheless, imitation learning is a somewhat dissatisfying approximation to programming from a computer science perspective, lacks some essential detail its practitioners consider important, and generally just creates more code to manage. Helpful though it may be for tedious chores, programmers are not just pattern matching on each others' code, but doing something more. Something that requires imagination, creativity, problem-solving. What could that be?

  \section{Knowledge Discovery and Neural Code Search}

  Search is an indispensable aspect of computer programming.

  \section{Computer-Aided Reasoning Tools}

  \section{Automatic and Synthetic Programming}

  \section{Future Directions of Computer Programming}

  \section{Conclusion}

  \bibliography{literature_review}
  \bibliographystyle{plain}
\end{document}