%! Author = breandanconsidine
%! Date = 8/9/21

% Preamble
\documentclass[10pt]{article}

% Packages
\usepackage{amsmath}

% Document
\title{Programming in the Age of Intelligent Machines}
\author{Breandan Considine}
\date{\today}

\begin{document}
  \maketitle
  \section{Introduction}

Since the invention of modern computers in the mid 20th century, computer programming has undergone a number of paradigm shifts. From the rise of functional programming, to dynamic, object-oriented, and type-level programming, to the availability of myriad tools and frameworks -- its practitioners have witnessed a veritable Renaissance in the art of computer programming. With each of these paradigm shifts, programmers have realized new conceptual frameworks for reasoning and expressing their ideas more clearly and concisely.

Over the last few years, another paradigm shift has been set in motion, with significant implications for how we think about and write programs in the coming century. By most measures, computers have grown steadily more intelligent and capable of assisting programmers with mentally taxing chores. For example, intelligent programming tools (IPTs) powered by neural language models have this year helped over 10 million unique human beings program computers. As IPTs help digitally illiterate communities to discover their innate aptitude for computer programming, this population will continue to rise.

The art of computer programming is a uniquely creative exercise among the range of human activities. It channels our innate linguistic, logical, imaginative, and social abilities to bring abstract ideas into reality, and ultimately, gives humans the freedom to create new realities of their own design. In collaboration with fellow humans and the increasing participation of IPTs, vast and elaborate virtual worlds have been manufactured, where the majority of humankind now chooses to spend their daily lives. As these new digital frontiers offer increasingly compelling relocation benefits, their population too will continue to grow.

Today IPTs share an equal role in shaping many aspects of computer programming, from knowledge discovery to API design, and program synthesis to validation and verification. However, this balance is shifting beneath our feet. Once its creators, programmers are now primarily consumers of information provided by an IPT, and increasingly rely on them to perform their daily work. With the unique opportunities and risks their partnership presents, what division of labor should exist between humans and their programming assistants? This is the question we set out to understand in the following literature review.

  \section{Neural Language Models for Source Code}

Programming researchers have long held an interest in using intelligent tools to help write programs~\cite{bras1993artificial}. Due to fundamental limitations in data and processing power, many of these ideas could not be fully realized until recently, thanks in part to the development of transformer-based models~\cite{vaswani2017attention} capable of learning more complex languages with longer-range dependencies. Other developments, such as more efficient representations and learning algorithms~\cite{allamanis2018survey} have contributed to the renewed interest in this research direction.

Since then, an enormous number of transformer-based models have been published and researchers have made rapid progress in industrial transfer, where this technology is now trained and deployed on millions of programmers worldwide~\cite{chen2021evaluating}. By training on open source data collected from GitHub, these models are capable of inferring the programmer's intent and completing long fragments of source code given some contextual information.

  \section{Knowledge Discovery and Neural Code Search}

  \section{Computer-Aided Reasoning Tools}

  \section{Automatic and Synthetic Programming}

  \section{Future Directions of Computer Programming}

  \section{Conclusion}

  \bibliography{literature_review}
  \bibliographystyle{plain}
\end{document}