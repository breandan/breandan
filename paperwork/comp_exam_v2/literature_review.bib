@article{bras1993artificial,
    title={Artificial intelligence tools for software engineering: Processing natural language requirements},
    author={Bras, M and Toussaint, Y},
    journal={WIT Transactions on Information and Communication Technologies},
    volume={2},
    year={1993},
    publisher={WIT Press}
}

@article{allamanis2018survey,
    title={A survey of machine learning for big code and naturalness},
    author={Allamanis, Miltiadis and Barr, Earl T and Devanbu, Premkumar and Sutton, Charles},
    journal={ACM Computing Surveys (CSUR)},
    volume={51},
    number={4},
    pages={1--37},
    year={2018},
    publisher={ACM New York, NY, USA}
}

@inproceedings{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    booktitle={Advances in neural information processing systems},
    pages={5998--6008},
    year={2017}
}

@article{chen2021evaluating,
    title={Evaluating large language models trained on code},
    author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Ponde, Henrique and Kaplan, Jared and Edwards, Harri and Burda, Yura and Joseph, Nicholas and Brockman, Greg and others},
    journal={arXiv preprint arXiv:2107.03374},
    year={2021}
}

@article{bhattamishra2020ability,
    title={On the ability and limitations of transformers to recognize formal languages},
    author={Bhattamishra, Satwik and Ahuja, Kabir and Goyal, Navin},
    journal={arXiv preprint arXiv:2009.11264},
    year={2020}
}